[#observing-environments]
= Observability configuration

Continue reading to understand what metrics can be collected with the observability compnent, and for information about the observability pod capacity.

[#metric-types]
== Metric types

By default, {ocp-short} sends metrics to Red Hat using the Telemetry service. The `acm_managed_cluster_info` is available with {product-title-short} and is included with telemetry, but is _not_ displayed on the {product-title-short} _Observe environments overview_ dashboard.

View the following table of metric types that are supported by the framework:

.Parameter table
|===
| Metric name | Metric type | Labels/tags | Status

| `acm_managed_cluster_info`
| Gauge
| `hub_cluster_id`, `managed_cluster_id`, `vendor`, `cloud`, `version`, `available`, `created_via`, `core_worker`, `socket_worker`
| Stable

| `config_policies_evaluation_duration_seconds_bucket`
| Histogram
| None
| Stable. Read _Governance metric_ for more details.

| `config_policies_evaluation_duration_seconds_count`
| Histogram
| None
| Stable. Refer to _Governance metric_ for more details.

| `config_policies_evaluation_duration_seconds_sum`
| Histogram
| None
| Stable. Read _Governance metric_ for more details.

| `policy_governance_info`
| Gauge
| `type`, `policy`, `policy_namespace`, `cluster_namespace`
| Stable. Review _Governance metric_ for more details.

| `policyreport_info`
| Gauge
| `managed_cluster_id`, `category`, `policy`, `result`, `severity`
| Stable. Read _Managing insight _PolicyReports__ for more details.

| `search_api_db_connection_failed_total`
| Counter
| None
| Stable. See the _Search components_ section in the _Searching in the console introduction_ documentation.

| `search_api_dbquery_duration_seconds`
| Histogram
| None
| Stable. See the _Search components_ section in the _Searching in the console introduction_ documentation.

| `search_api_requests`
| Histogram
| None
| Stable. See the _Search components_ section in the _Searching in the console introduction_ documentation.

| `search_indexer_request_count`
| Counter
| None
| Stable. See the _Search components_ section in the _Searching in the console introduction_ documentation.

| `search_indexer_request_duration`
| Histogram
| None
| Stable. See the _Search components_ section in the _Searching in the console introduction_ documentation.

| `search_indexer_requests_in_flight`
| Gauge
| None
| Stable. See the _Search components_ section in the _Searching in the console introduction_ documentation.

| `search_indexer_request_size`
| Histogram
| None
| Stable. See the _Search components_ section in the _Searching in the console introduction_ documentation.
|===

[#observability-pod-capacity-requests]
== Observability pod capacity requests

Observability components require 2701mCPU and 11972Mi memory to install the observability service. The following table is a list of the pod capacity requests for five managed clusters with `observability-addons` enabled:

.Observability pod capacity requests
|===
| Deployment or StatefulSet | Container name | CPU (mCPU) | Memory (Mi) | Replicas | Pod total CPU | Pod total memory 

.3+| observability-alertmanager 
| alertmanager 

| 4
| 200
| 3
| 12
| 600

| config-reloader
| 4
| 25
| 3
| 12
| 75

| alertmanager-proxy
| 1
| 20
| 3
| 3
| 60

.2+| observability-grafana

| grafana
| 4
| 100
| 2
| 8
| 200

| grafana-dashboard-loader
| 4
| 50
| 2
| 8
| 100

| observability-observatorium-api
| observatorium-api
| 20
| 128
| 2
| 40
| 256

| observability-observatorium-operator
| observatorium-operator
| 100
| 100
| 1
| 10
| 50

.2+| observability-rbac-query-proxy
| rbac-query-proxy
| 20
| 100
| 2
| 40
| 200

| oauth-proxy
| 1
| 20
| 2
| 2
| 40

| observability-thanos-compact
| thanos-compact
| 100
| 512
| 1
| 100
| 512

| observability-thanos-query
| thanos-query
| 300
| 1024
| 2
| 600
| 2048

| observability-thanos-query-frontend
| thanos-query-frontend
| 100
| 256
| 2
| 200
| 512

.2+| observability-thanos-query-frontend-memcached
| memcached
| 45
| 128
| 3
| 135
| 384

| exporter
| 5
| 50
| 3
| 15
| 150

| observability-thanos-receive-controller
| thanos-receive-controller
| 4
| 32
| 1
| 4
| 32

| observability-thanos-receive-default
| thanos-receive
| 300
| 512
| 3
| 900
| 1536

.2+| observability-thanos-rule
| thanos-rule
| 50
| 512
| 3
| 150
| 1536

| configmap-reloader
| 4
| 25
| 3
| 12
| 75

.2+| observability-thanos-store-memcached
| memcached
| 45
| 128
| 3
| 135
| 384

| exporter
| 5
| 50
| 3
| 15
| 150

| observability-thanos-store-shard
| thanos-store
| 100
| 1024
| 3
| 300
| 3072
|===

//should Dynamic metrics for single-node OpenShift clusters section be added here? | MJ | 09/26/23
[#dynamic-metrics-for-sno]
=== Dynamic metrics for single-node OpenShift clusters

Dynamic metrics collection supports automatic metric collection based on certain conditions. By default, a SNO cluster does not collect pod and container resource metrics. Once a SNO cluster reaches a specific level of resource consumption, the defined granular metrics are collected dynamically. When the cluster resource consumption is consistently less than the threshold for a period of time, granular metric collection stops.

The metrics are collected dynamically based on the conditions on the managed cluster specified by a collection rule. Because these metrics are collected dynamically, the following {product-title-short} Grafana dashboards do not display any data. When a collection rule is activated and the corresponding metrics are collected, the following panels display data for the duration of the time that the collection rule is initiated:

* Kubernetes/Compute Resources/Namespace (Pods)
* Kubernetes/Compute Resources/Namespace (Workloads)
* Kubernetes/Compute Resources/Nodes (Pods)
* Kubernetes/Compute Resources/Pod
* Kubernetes/Compute Resources/Workload
A collection rule includes the following conditions:

* A set of metrics to collect dynamically.
* Conditions written as a PromQL expression.
* A time interval for the collection, which must be set to `true`.
* A match expression to select clusters where the collect rule must be evaluated.
By default, collection rules are evaluated continuously on managed clusters every 30 seconds, or at a specific time interval. The lowest value between the collection interval and time interval takes precedence. Once the collection rule condition persists for the duration specified by the `for` attribute, the collection rule starts and the metrics specified by the rule are automatically collected on the managed cluster. Metrics collection stops automatically after the collection rule condition no longer exists on the managed cluster, at least 15 minutes after it starts.

The collection rules are grouped together as a parameter section named `collect_rules`, where it can be enabled or disabled as a group. {product-title-short} installation includes the collection rule group, `SNOResourceUsage` with two default collection rules: `HighCPUUsage` and `HighMemoryUsage`. The `HighCPUUsage` collection rule begins when the node CPU usage exceeds 70%. The `HighMemoryUsage` collection rule begins if the overall memory utilization of the SNO cluster exceeds 70% of the available node memory. Currently, the previously mentioned thresholds are fixed and cannot be changed. When a collection rule begins for more than the interval specified by the `for` attribute, the system automatically starts collecting the metrics that are specified in the `dynamic_metrics` section.

View the list of dynamic metrics that from the `collect_rules` section, in the following YAML file:

[source,yaml]
----
collect_rules:
  - group: SNOResourceUsage
    annotations:
      description: >
        By default, a SNO cluster does not collect pod and container resource metrics. Once a SNO cluster 
        reaches a level of resource consumption, these granular metrics are collected dynamically. 
        When the cluster resource consumption is consistently less than the threshold for a period of time, 
        collection of the granular metrics stops.
    selector:
      matchExpressions:
        - key: clusterType
          operator: In
          values: ["SNO"]
    rules:
    - collect: SNOHighCPUUsage
      annotations:
        description: >
          Collects the dynamic metrics specified if the cluster cpu usage is constantly more than 70% for 2 minutes
      expr: (1 - avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m]))) * 100 > 70
      for: 2m
      dynamic_metrics:
        names:
          - container_cpu_cfs_periods_total
          - container_cpu_cfs_throttled_periods_total
          - kube_pod_container_resource_limits 
          - kube_pod_container_resource_requests   
          - namespace_workload_pod:kube_pod_owner:relabel 
          - node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate 
          - node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate 
    - collect: SNOHighMemoryUsage
      annotations:
        description: >
          Collects the dynamic metrics specified if the cluster memory usage is constantly more than 70% for 2 minutes
      expr: (1 - sum(:node_memory_MemAvailable_bytes:sum) / sum(kube_node_status_allocatable{resource=\"memory\"})) * 100 > 70
      for: 2m
      dynamic_metrics:
        names:
          - kube_pod_container_resource_limits 
          - kube_pod_container_resource_requests 
          - namespace_workload_pod:kube_pod_owner:relabel
        matches:
          - __name__="container_memory_cache",container!=""
          - __name__="container_memory_rss",container!=""
          - __name__="container_memory_swap",container!=""
          - __name__="container_memory_working_set_bytes",container!=""
----

A `collect_rules.group` can be disabled in the `custom-allowlist` as shown in the following example. When a `collect_rules.group` is disabled, metrics collection reverts to the previous behavior. These metrics are collected at regularly, specified intervals:

[source,yaml]
----
collect_rules:
  - group: -SNOResourceUsage
---- 

The data is only displayed in Grafana when the rule is initiated.

[#additional-resources-obs]
== Additional resources

- For more information about enabling observability, read xref:../observability/observability_enable.adoc#managing-observability-service[Managing the observability service].
- Read xref:../observability/customize_observability.adoc#customizing-observability[Customizing observability] to learn how to configure the observability service, view metrics and other data.
- Read xref:../observability/design_grafana.adoc#using-grafana-dashboards[Using Grafana dashboards].
- Learn from the {ocp-short} documentation what types of metrics are collected and sent using telemetry. See link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/support/index#about-remote-health-monitoring[Information collected by Telemetry] for information. 
- Refer to link:../governance/policy_ctrl_adv_config.adoc#gov-metric[Governance metric] for details.
- Read xref:../observability/manage_insights.adoc#manage-insights[Managing insight _PolicyReports_].
- Refer to link:https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/[Prometheus recording rules].
- Also refer to link:https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/[Prometheus alerting rules].
- Return to xref:../observability/observe_environments_intro.adoc#observing-environments-intro[Observability service introduction].
